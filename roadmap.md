# ğŸ¯ Roadmap Immo-Bot â€” Recommandations Claude Code

> Analyse complÃ¨te de l'Ã©tat actuel, corrections hier (24 fÃ©v), et direction future

---

## ğŸ“Š Ã‰tat Actuel (25 fÃ©vrier 2026)

### Dashboard
- **Status:** MVP ~75% (fonctionnel, features avancÃ©es incomplÃ¨tes)
- **DonnÃ©es:** 132 annonces, 77 villes, 6 sites, 94.7% GPS coverage
- **Hier (24 fÃ©v):** 81 corrections bugs HTML/syntaxe (accolades, Jinja2)

### Bot Scraping
- **Status:** v2.6 production (7/9 scrapers actifs)
- **DerniÃ¨re action:** Pagination tous scrapers (+309 annonces)
- **ProblÃ¨mes:** 2/9 sites bloquÃ©s (Wortimmo, Immoweb)

### Architecture
- **2 gÃ©nÃ©rateurs redondants:** `dashboard_generator.py` vs `dashboard.py` (confusion)
- **Filtrage dupliquÃ©:** Dans 9 scrapers + main.py (maintenance cauchemar)
- **Pas d'async:** Boucle scraping = 2-3 min (sÃ©quentiel)
- **Pas de tests:** ZÃ©ro couverture (risque rÃ©gression)

---

## ğŸ”§ Correction Hier (24 fÃ©vrier) â€” Analyse

**SymptÃ´me:** 81 commits = "regenerer dashboard - TOUS les bugs fixes 1-81"

**Diagnostic probable:**
- Template HTML avait accolades mal fermÃ©es (`{{}}` malformÃ©)
- Variables Jinja2 non Ã©chappÃ©es
- Syntaxe Bootstrap/Leaflet incohÃ©rente
- RÃ©sultat: HTML impossible Ã  parser â†’ correction massive

**LeÃ§on:** PrÃ©fÃ©rer `dashboard_generator.py` (Python-safe) vs `dashboard.py` (template error-prone)

---

## âœ… Recommandations â€” DÃ©marche ACTUELLE (Dashboard)

### Phase 1: Stabilisation & Nettoyage (2-3 jours)

| Action | Effort | PrioritÃ© | Raison |
|--------|--------|----------|--------|
| **Supprimer `dashboard.py`** | 5 min | ğŸ”´ URGENT | Redondant + confusing |
| **Supprimer `templates/dashboard.html`** | 5 min | ğŸ”´ URGENT | ConÃ§u pour API inexistant |
| **Supprimer `templates/` dir vide** | 2 min | ğŸŸ¡ MOYEN | Cleanup |
| **Valider 100% listings sans erreur HTML** | 10 min | ğŸ”´ URGENT | QA pipeline |
| **Test end-to-end:** `python dashboard_generator.py` â†’ ouvrir HTML | 15 min | ğŸ”´ URGENT | Validation workflow |

**RÃ©sultat:** Codebase propre, une seule source de vÃ©ritÃ© (`dashboard_generator.py`)

---

### Phase 2: ComplÃ©ter Features (3-5 jours)

Actuellement 8 tabs, dont 3 incomplets:

| Tab | Status | Effort | Action |
|-----|--------|--------|--------|
| ğŸ“‹ **Tableau** | âœ… Complet | â€” | Rien |
| ğŸ“Š **Sites (Charts)** | âŒ Manquant | 30min | Initialiser Chart.js doughnut |
| ğŸ“ **Villes (Charts)** | âŒ Manquant | 30min | Initialiser Chart.js bar |
| ğŸ’° **Par prix** | âœ… Complet | â€” | Rien |
| ğŸ—ºï¸ **Carte** | âœ… Complet | â€” | Rien |
| ğŸ”¥ **DensitÃ©** | âŒ Manquant | 45min | Heatmap canvas + calculs |
| ğŸ“ˆ **Timeline** | âŒ Manquant | 1h | Slider interactif dates historiques |
| ğŸš¨ **Anomalies** | âŒ Manquant | 1h | Detection + flagging outliers |

**MVP minimum:** Chart.js (2 tabs) + Timeline (1 tab) = 2h
**Complet:** + Heatmap + Anomalies = 4h supplÃ©mentaires

**Priorisation recommandÃ©e:**
1. Chart.js (haute valeur, facile)
2. Timeline (moyenne valeur, facile)
3. Heatmap (bonus, moyen effort)
4. Anomalies (bonus, moyen effort)

---

### Phase 3: Production-Ready (1 semaine)

- [ ] Ajouter **logging** dans `dashboard_generator.py` (fichier JSON avec timestamps)
- [ ] Ajouter **tests pytest** (vÃ©rifier HTML valide, donnÃ©es complÃ¨tes, pas d'erreurs JS)
- [ ] **Monitoring:** GPS coverage alert si <90%
- [ ] **Archiving:** Cleanup automatique archives >30 jours
- [ ] **PWA versioning:** Service worker timestamp auto-update
- [ ] **Documentation:** Ajouter section Dashboard dans architecture.md

---

## ğŸš€ Recommandations â€” DÃ©marche FUTURE

### Timeline ProposÃ©

```
Semaine 1   : Dashboard stabilisation + Chart.js
Semaine 2   : Dashboard complet (Timeline, Heatmap, Anomalies) + Tests
PAUSE BREAK : Valider dashboard en production

Semaine 3   : Async scrapers (PRIORITÃ‰ HAUTE)
Semaine 4   : Centraliser filtrage + tests scrapers
Semaine 5-6 : Remplacer Wortimmo/Immoweb + tests intÃ©gration
Semaine 7-8 : Tests end-to-end complets
```

---

### Async Scrapers (Semaine 3) â€” PRIORITÃ‰ ğŸ”´ HAUTE

**ProblÃ¨me actuel:** Boucle scraping = 2-3 minutes (sÃ©quentiel)
```
Athome (15s) â†’ Immotop (10s) â†’ Luxhome (8s) â†’ VIVI (20s) â†’ ...
â†’ Total: 60-120s = attendre longtemps entre cycles
```

**Solution async:**
```
Athome (15s)    â”
Immotop (10s)   â”‚ En parallÃ¨le
Luxhome (8s)    â”‚ = <30sec total
VIVI (20s)      â”¤
Nextimmo (12s)  â”‚
...             â”˜
```

**Effort:** 1 semaine (3-4 jours refactoring + tests)
**Impact:** ğŸ”´ CRITIQUE (UX, rÃ©activitÃ©, Telegram notifications plus rapides)
**Technique:** `asyncio` + `aiohttp` (drop Selenium â†’ Playwright async pour durÃ©e)

**Ã‰tapes:**
1. Refactor scrapers HTTP (Athome, Immotop, Nextimmo, Luxhome) â†’ async
2. Garder Selenium (VIVI, Newimmo, Unicorn) synchrone (complexe async)
3. Lancer mix async + sync en parallÃ¨le dans main.py
4. Mesurer before/after timing
5. Progressivement migrer Selenium â†’ Playwright async

---

### Centraliser Filtrage (Semaine 4) â€” PRIORITÃ‰ ğŸŸ¡ MOYEN

**ProblÃ¨me:** `_matches_criteria()` dupliquÃ© dans 9 scrapers + main.py
```
athome_scraper.py:       if price < MIN_PRICE: continue
immotop_scraper.py:      if price < MIN_PRICE: continue
luxhome_scraper.py:      if price < MIN_PRICE: continue
...
main.py:                 if not _matches_criteria(listing): continue
```
â†’ Maintenance cauchemar, inconsistances, hard Ã  tester

**Solution:**
```python
# utils.py â€” CENTRALISÃ‰
def apply_criteria(listing):
    """Filtre unique pour tous scrapers + main.py"""
    if listing['price'] < MIN_PRICE: return False
    if listing['rooms'] < MIN_ROOMS: return False
    ...
    return True

# Utilisation:
for listing in scraper.scrape():
    if apply_criteria(listing):
        db.insert(listing)
```

**Effort:** 2-3 jours
**Impact:** ğŸŸ¡ MOYEN (maintenance + robustesse)

**Ã‰tapes:**
1. CrÃ©er `utils.py:apply_criteria()` centralisÃ© (copiÃ©e de main.py)
2. Importer dans tous 9 scrapers (remplacer code local)
3. Main.py applique au 2e level (double-check + dedup)
4. Tests: vÃ©rifier mÃªme rÃ©sultat avant/aprÃ¨s

---

### Remplacer Wortimmo/Immoweb (Semaine 5-6) â€” PRIORITÃ‰ ğŸŸ¡ MOYEN

**Blocage:** 2/9 sites inaccessibles
- **Wortimmo:** Cloudflare bloque donnees listing (prix = dropdown filtres)
- **Immoweb:** CAPTCHA bloque page 1

**Objectif:** Trouver 2 nouveaux sites luxembourgeois (10-20% annonces de plus)

**Recherche recommandÃ©e:**
- Portails immobiliers luxembourgeois non-scrapÃ©s
- Sites "proprios" (direct propriÃ©taires) ou agences taille moyenne
- VÃ©rifier robots.txt + ToS (lÃ©galitÃ© scraping)
- Ã‰viter Cloudflare/CAPTCHA

**Candidats potentiels:**
- Portails immobiliers rÃ©gionaux (Lorraine/Wallonie avec prix LU)
- Annonces "Facebook Marketplace Luxembourg"
- Agences indÃ©pendantes JSON APIs (si publiques)

**Effort par site:** 3-5 jours (exploration + dev + tests)
**Impact:** ğŸŸ¡ MOYEN (+15-20% annonces)

---

### Tests AutomatisÃ©s (Semaine 7-8) â€” PRIORITÃ‰ ğŸŸ¡ MOYEN/LONG-TERME

**Status actuel:** ZÃ©ro tests (risk ğŸ”´ CRITIQUE)

**Couverture recommandÃ©e:**

| Module | Tests | Effort | Impact |
|--------|-------|--------|--------|
| **Scrapers** | Unit tests (mock API + HTML) | 1 jour | Haut |
| **Database** | Integration tests (SQLite temp) | 1 jour | Haut |
| **Dedup** | Edge cases (similar listings) | 1 jour | Haut |
| **Notifier** | Mock Telegram API | 1 jour | Moyen |
| **Utils** | GPS distance, geocoding | 1 jour | Bas |
| **Dashboard** | HTML validation, JS errors | 1 jour | Moyen |

**Framework:** pytest (standard Python)
**Minimum viable:** 60% couverture (scrapers + DB + dedup)

---

## ğŸ“ˆ Matrice PrioritÃ©s

### Impact vs Effort (Bulle plot)

```
HIGH IMPACT, LOW EFFORT (DO NOW):
  âœ… Dashboard Chart.js              (30min, haute valeur)
  âœ… Dashboard Timeline              (1h, haute valeur)
  âœ… Supprimer code legacy           (10min, critique cleanup)

HIGH IMPACT, HIGH EFFORT (DO SOON):
  âš ï¸ Async scrapers                 (3-4 jours, critique perf)
  âš ï¸ Tests pytest                   (5-6 jours, critique robustesse)

MEDIUM IMPACT, MEDIUM EFFORT:
  ğŸŸ¡ Centraliser filtrage           (2-3 jours, maintenance)
  ğŸŸ¡ Remplacer Wortimmo/Immoweb     (5-6 jours, +annonces)

LOW IMPACT, HIGH EFFORT (SKIP):
  âŒ Dashboard Heatmap              (45min, insight bonus)
  âŒ Dashboard Anomalies            (1h, insight bonus)
```

---

## ğŸ“‹ Action Items â€” PrÃªt Ã  ExÃ©cuter

### IMMÃ‰DIAT (2-3 jours)
- [ ] Supprimer `dashboard.py` (5 min)
- [ ] Supprimer `templates/dashboard.html` (5 min)
- [ ] Valider HTML sans erreurs (10 min)
- [ ] Test end-to-end dashboard_generator.py (15 min)
- [ ] Ajouter Chart.js initialisation (30 min)
- [ ] Ajouter Timeline interactif (1h)

**Commit:** `dashboard: cleanup legacy + chart.js + timeline`

---

### COURT-TERME (4-5 jours)
- [ ] Ajouter Heatmap visualization (45 min)
- [ ] Ajouter Anomalies detection (1h)
- [ ] Ajouter tests pytest (1-2 jours)
- [ ] Ajouter logging/monitoring (2h)
- [ ] Mettre Ã  jour CLAUDE.md version dashboard (30 min)

**Commits:**
- `dashboard: add heatmap`
- `dashboard: add anomalies detection`
- `dashboard: add pytest coverage`
- `dashboard: v1.0 production-ready`

---

### MOYEN-TERME (Semaines 3-4)
- [ ] Async scrapers implementation
- [ ] Centraliser filtrage
- [ ] Tests scrapers unit

**Commits:**
- `scrapers: async http implementation`
- `utils: centralize criteria filtering`
- `tests: add pytest scrapers coverage`

---

### LONG-TERME (Semaines 5-8)
- [ ] Trouver + implÃ©menter 2 nouveaux scrapers
- [ ] Tests integration DB + dedup
- [ ] Tests end-to-end dashboard + bot

---

## ğŸ¯ SuccÃ¨s Criteria

### Dashboard (Fin Semaine 2)
- âœ… ZÃ©ro code legacy
- âœ… Chart.js fonctionne (2 charts)
- âœ… Timeline fonctionne (10 dates archive)
- âœ… 100% listings affichÃ©s sans erreur
- âœ… Tests pytest passing (>80% couverture)
- âœ… Production-ready (logging + monitoring)

### Bot (Fin Semaine 8)
- âœ… Async scrapers: <30 sec par cycle (vs 2-3 min actuellement)
- âœ… Centralized filtering (1 source de vÃ©ritÃ©)
- âœ… 9/9 scrapers actifs (remplacer 2 bloquÃ©s)
- âœ… Tests coverage >70% (tous modules)
- âœ… ZÃ©ro rÃ©gression (tests rÃ©gression + monitoring)

---

## ğŸ“š Documents LiÃ©s

- **CLAUDE.md** â€” Contexte bot + instructions Claude Code
- **analyse.md** â€” Historique corrections + problÃ¨mes connus
- **architecture.md** â€” Flux technique complet
- **planning.md** â€” Dashboard HTML brief (ACTUEL)

---

## ğŸ’¡ Notes Finales

### Philosophie de dev
1. **Stabiliser d'abord** (dashboard MVP 100%)
2. **Puis optimiser** (async scrapers)
3. **Puis tester** (pytest coverage)
4. **Puis scaler** (nouveaux scrapers)

### ParallÃ©lisation
- âœ… Dashboard + Async scrapers PEUVENT tourner en parallÃ¨le (domaines indÃ©pendants)
- âŒ Dashboard + Centraliser filtrage = dÃ©pendance (filtrage affecte scrapers)
- âŒ Ne pas commencer async tant que tests scrapers manquent (risque rÃ©gression)

### Maintenance long-terme
- Lire CLAUDE.md + analyse.md Ã  chaque session
- Lancer diagnostic avant chaque action (scripts diagnostic)
- Tester avant committer
- Documenter corrections dans analyse.md

---

**DerniÃ¨re mise Ã  jour:** 25 fÃ©vrier 2026 â€” Claude Code analysis
**Branche:** claude/list-markdown-files-6PVxa
**PrÃªt Ã  exÃ©cuter aprÃ¨s approbation**
