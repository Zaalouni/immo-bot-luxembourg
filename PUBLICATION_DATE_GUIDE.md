# üìÖ Guide : R√©cup√©rer la date de publication des annonces

> **Analyse compl√®te** : Comment r√©cup√©rer la date de publication pour chaque scraper
> et l'int√©grer dans le dashboard pour filtrer les annonces par date.

---

## üìã Table des mati√®res

1. [Contexte et importance](#contexte-et-importance)
2. [√âtat actuel : analyse des 7 scrapers](#√©tat-actuel--analyse-des-7-scrapers)
3. [Strat√©gies de r√©cup√©ration par scraper](#strat√©gies-de-r√©cup√©ration-par-scraper)
4. [Modifications √† la base de donn√©es](#modifications-√†-la-base-de-donn√©es)
5. [Modifications aux scrapers](#modifications-aux-scrapers)
6. [Int√©gration dans le dashboard](#int√©gration-dans-le-dashboard)
7. [Plan d'ex√©cution (√©tapes)](#plan-dex√©cution-√©tapes)

---

## Contexte et importance

### Pourquoi la date est CRITIQUE

Vous lancez le bot **2 fois par jour minimum** ‚Üí besoin de savoir :
- ‚úÖ **Annonce publi√©e ce matin ?** (nouvelle, int√©ressante)
- ‚úÖ **Annonce publi√©e hier ?** (l√©g√®rement moins fra√Æche)
- ‚ùå **Annonce publi√©e il y a 2 semaines ?** (probablement pourvue ou obsol√®te)

### Cas d'usage dans le dashboard

```
Tableau annonces tri√©es par DATE D√âCROISSANTE:

üìÖ 2026-02-26 09:45 | Athome | 2ch, 1250‚Ç¨ | Luxembourg | ‚ú® NOUVELLE
üìÖ 2026-02-26 08:15 | Nextimmo | 3ch, 1800‚Ç¨ | Esch | ‚ú® NOUVELLE
üìÖ 2026-02-25 19:30 | VIVI | 2ch, 1500‚Ç¨ | Differdange | Hier
üìÖ 2026-02-25 14:20 | Luxhome | 1ch, 900‚Ç¨ | Dudelange | Hier
üìÖ 2026-02-24 10:00 | Immotop | 2ch, 1400‚Ç¨ | Luxembourg | 2 jours
```

### Strat√©gie robuste avec fallback

**Approche √† 2 niveaux** (tr√®s fiable) :

```
Niveau 1: Chercher date de publication du site
‚îú‚îÄ Si trouv√©e et valide ‚Üí utiliser
‚îú‚îÄ Si format incoh√©rent ou future ‚Üí rejeter
‚îî‚îÄ Si non trouv√©e ‚Üí Niveau 2

Niveau 2: Fallback √† date d'extraction
‚îú‚îÄ published_at = extraction_at (heure du scraping)
‚îî‚îÄ C'est la date MINIMALE s√ªre
```

### Donn√©es disponibles

- **Option 1** (Pr√©f√©r√©) : Date de publication r√©cup√©r√©e du site
- **Option 2** (Fallback fiable) : Date d'extraction de l'annonce = `datetime.now()` au moment du scraping

### Probl√®me et solution

**Probl√®me** :
- Parfois la date est visible dans le texte ("Il y a 2h")
- Parfois elle est dans un attribut JSON
- Parfois elle est compl√®tement absente ‚ùå

**Solution** :
- ‚úÖ Toujours avoir un fallback √† la date du scraping
- ‚úÖ Chaque annonce aura UNE date (m√™me si approxim√©e)
- ‚úÖ Pour le dashboard : published_at <= now() toujours

---

## √âtat actuel : analyse des 7 scrapers

### R√©sum√© rapide

| Scraper | Date publi | Format | R√©cup√©ration | S√©v√©rit√© | Effort |
|---------|-----------|--------|---------------|----------|--------|
| **Athome.lu** | ‚ùì Inconnue | ? | √Ä analyser | üî¥ CRITIQUE | Moyen |
| **Immotop.lu** | ‚úÖ Disponible | Text (ex: "il y a 2j") | Parsing texte | üü† MOYENNE | Petit |
| **Luxhome.lu** | ‚ùì Inconnue | ? | √Ä analyser | üî¥ CRITIQUE | Moyen |
| **VIVI.lu** | ‚úÖ Probable | Selenium | Trouver en HTML | üü† MOYENNE | Moyen |
| **Nextimmo.lu** | ‚úÖ API | JSON (timestamp?) | √Ä analyser | üü¢ BON | Petit |
| **Newimmo.lu** | ‚ùì Inconnue | ? | √Ä analyser | üî¥ CRITIQUE | Moyen |
| **Unicorn.lu** | ‚ùì Inconnue | ? | √Ä analyser | üî¥ CRITIQUE | Moyen |

---

## Strat√©gies de r√©cup√©ration par scraper

### 1Ô∏è‚É£ Athome.lu

**Scraper** : `scrapers/athome_scraper_json.py`

**Analyse** :
```python
# JSON __INITIAL_STATE__ peut contenir:
item = {
    'id': 123,
    'price': 1250,
    'publishDate': '2026-02-26T09:45:00Z',  # ‚Üê √Ä chercher?
    'createdAt': '2026-02-26T09:45:00Z',   # ‚Üê √Ä chercher?
    'timestamp': 1708934700,                # ‚Üê √Ä chercher?
    'time_ago': 'Il y a 2 heures',         # ‚Üê Parsing texte?
}
```

**Actions n√©cessaires** :
1. ‚úÖ V√©rifier JSON pour cl√© `publishDate`, `createdAt`, `timestamp`, ou `time_ago`
2. ‚úÖ Si trouv√© : extraire et parser en `datetime`
3. ‚úÖ Si non trouv√© : fallback √† date d'extraction

**Exemple attendu** :
```python
# Dans _extract_listing():
published_at = None
for key in ['publishDate', 'createdAt', 'timestamp', 'time_ago']:
    if key in item:
        published_at = parse_date_athome(item[key])
        break

# Ajouter au retour:
'published_at': published_at  # datetime ou None
```

**Probabilit√© de succ√®s** : 60% (sites web fran√ßais souvent expose cette info)

---

### 2Ô∏è‚É£ Immotop.lu

**Scraper** : `scrapers/immotop_scraper_real.py`

**Analyse** :
```python
# Immotop affiche g√©n√©ralement:
# "Il y a 2 heures", "Il y a 1 jour", "R√©cemment", etc.
# Format regex √† chercher dans contexte HTML
pattern = r"[Ii]l y a (\d+)\s*(?:heures|jours|semaines)"
```

**Donn√©es disponibles** :
```
Texte visible : "Il y a 2 heures"
‚Üí Convertir en datetime : datetime.now() - timedelta(hours=2)

Texte visible : "Il y a 1 jour"
‚Üí Convertir en datetime : datetime.now() - timedelta(days=1)
```

**Actions n√©cessaires** :
1. ‚úÖ Extraire texte "il y a X..." depuis contexte HTML
2. ‚úÖ Parser nombre + unit√© (heures/jours/semaines)
3. ‚úÖ Calculer datetime = now() - timedelta

**Exemple** :
```python
import re
from datetime import datetime, timedelta

def parse_immotop_date(text):
    """Extraire "il y a X jours" et convertir en datetime"""
    match = re.search(r"[Ii]l y a (\d+)\s*(?:heure|jour|semaine)s?", text)
    if match:
        number = int(match.group(1))
        if 'heure' in match.group(0):
            return datetime.now() - timedelta(hours=number)
        elif 'jour' in match.group(0):
            return datetime.now() - timedelta(days=number)
        elif 'semaine' in match.group(0):
            return datetime.now() - timedelta(weeks=number)
    return None
```

**Probabilit√© de succ√®s** : 85% (texte visible g√©n√©ralement)

---

### 3Ô∏è‚É£ Luxhome.lu

**Scraper** : `scrapers/luxhome_scraper.py`

**Analyse** :
```python
# JSON embarqu√© peut contenir:
pattern = r'\{"title":"...","published":"2026-02-26T...",\s*...'
# Chercher cl√© "published", "date", "createdAt", etc.
```

**Actions n√©cessaires** :
1. ‚úÖ Analyser regex JSON pour cl√©s de date
2. ‚úÖ Extraire et parser en datetime
3. ‚úÖ Fallback √† `time_ago` si pr√©sent

**Probabilit√© de succ√®s** : 60%

---

### 4Ô∏è‚É£ VIVI.lu

**Scraper** : `scrapers/vivi_scraper_selenium.py`

**Analyse** :
```python
# Selenium acc√®de au DOM complet
# Date peut √™tre dans:
# - <span class="date">26/02/2026</span>
# - <time datetime="2026-02-26T09:45:00"></time>
# - Texte: "Publi√© le 26 f√©vrier 2026"
```

**Actions n√©cessaires** :
1. ‚úÖ Chercher `<time>` element avec datetime
2. ‚úÖ Ou chercher span/div avec classe "date", "published", etc.
3. ‚úÖ Parser en datetime

**Exemple** :
```python
from selenium.webdriver.common.by import By

# Dans _extract_listing():
try:
    time_elem = card.find_element(By.CSS_SELECTOR, 'time[datetime]')
    datetime_str = time_elem.get_attribute('datetime')
    published_at = datetime.fromisoformat(datetime_str.replace('Z', '+00:00'))
except:
    published_at = None
```

**Probabilit√© de succ√®s** : 70%

---

### 5Ô∏è‚É£ Nextimmo.lu

**Scraper** : `scrapers/nextimmo_scraper.py`

**Analyse** :
```python
# API JSON peut retourner:
item = {
    'id': 123,
    'createdAt': '2026-02-26T09:45:00Z',  # ‚Üê √Ä chercher
    'publishedAt': '2026-02-26T09:45:00Z', # ‚Üê √Ä chercher
    'updatedAt': '2026-02-26T10:30:00Z',  # ‚Üê √Ä chercher (attention: mise √† jour, pas cr√©ation)
    'created': 1708934700,                 # ‚Üê Timestamp Unix?
}
```

**Actions n√©cessaires** :
1. ‚úÖ Analyser JSON API pour cl√©s date
2. ‚úÖ Extraire `createdAt` ou `publishedAt` (pas `updatedAt`)
3. ‚úÖ Parser en datetime (format ISO 8601)

**Exemple** :
```python
# Dans _extract_from_json():
published_at = None
date_str = item.get('createdAt') or item.get('publishedAt')
if date_str:
    try:
        published_at = datetime.fromisoformat(date_str.replace('Z', '+00:00'))
    except:
        pass
```

**Probabilit√© de succ√®s** : 80% (API g√©n√©ralement propre)

---

### 6Ô∏è‚É£ Newimmo.lu

**Scraper** : `scrapers/newimmo_scraper_real.py`

**Analyse** :
```python
# Extraction depuis page_source (regex sur HTML)
# Chercher texte visible: "Publi√© le 26/02/2026"
# Ou attribut data-date="2026-02-26"
pattern = r'publi[√©e]?\s*(?:le\s+)?(\d{1,2}/\d{1,2}/\d{4})'
```

**Actions n√©cessaires** :
1. ‚úÖ Regex pour "Publi√© le DD/MM/YYYY"
2. ‚úÖ Parser en datetime

**Probabilit√© de succ√®s** : 50% (regex fragile)

---

### 7Ô∏è‚É£ Unicorn.lu

**Scraper** : `scrapers/unicorn_scraper_real.py`

**Analyse** :
```python
# Extraction depuis page_source (regex sur HTML)
# Chercher dans contexte HTML: attributs data-date, texte visible, etc.
pattern = r'<time[^>]*>([^<]+)</time>'
pattern = r'[Dd]epuis?\s*(\d+\s*(?:heures|jours|semaines))'
```

**Actions n√©cessaires** :
1. ‚úÖ Chercher `<time>` dans contexte
2. ‚úÖ Ou extraire "depuis X jours" et calculer datetime
3. ‚úÖ Parser en datetime

**Probabilit√© de succ√®s** : 55%

---

## Strat√©gie de fallback garantie

### Architecture robuste

```
Chaque scraper :
1. Tente extraire published_at du site
2. Si √©choue : published_at = None (pas d'erreur)
3. Avant retour : fallback √† datetime.now()

result = {
    'listing_id': ...,
    'published_at': published_at or datetime.now()  # ‚Üê FALLBACK GARANTIE
}
```

### Logique en pseudocode

```python
def extract_with_fallback_date(item, scraper_name):
    """Extraire annonce avec date, GARANTIE fallback"""

    # 1. Extraire annonce (prix, titre, etc.)
    listing = {
        'listing_id': ...,
        'site': scraper_name,
        'title': ...,
        'price': ...,
        ...
    }

    # 2. TOUJOURS extraire date de publication
    published_at = extract_date_from_item(item)  # Peut retourner None

    # 3. FALLBACK GARANTI
    if published_at is None:
        published_at = datetime.now()  # Date du scraping = date min s√ªre

    # 4. VALIDATION: date ne peut pas √™tre dans le futur
    if published_at > datetime.now():
        published_at = datetime.now()  # Correction √† maintenant

    listing['published_at'] = published_at
    return listing
```

### Tableau: Fiabilit√© par scraper

| Scraper | Chance date | Fallback | Fiabilit√© |
|---------|-----------|----------|-----------|
| Nextimmo | 85% | ‚úÖ Oui | 100% |
| Athome | 60% | ‚úÖ Oui | 100% |
| Immotop | 85% | ‚úÖ Oui | 100% |
| VIVI | 70% | ‚úÖ Oui | 100% |
| Luxhome | 60% | ‚úÖ Oui | 100% |
| Newimmo | 50% | ‚úÖ Oui | 100% |
| Unicorn | 55% | ‚úÖ Oui | 100% |

**Conclusion** : Tous les scrapers auront 100% de couverture de date (published_at jamais None)

---

## Modifications √† la base de donn√©es

### Sch√©ma nouvelle colonne

**Fichier** : `database.py`

**Ajouter colonne** :
```sql
ALTER TABLE listings ADD COLUMN published_at TIMESTAMP;
CREATE INDEX idx_published_at ON listings(published_at);
```

**Ou dans init_db()** (pour nouvelles instances) :
```python
def init_db(self):
    ...
    self.cursor.execute('''
        CREATE TABLE IF NOT EXISTS listings (
            ...
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            published_at TIMESTAMP,  # ‚Üê NOUVELLE: date publication du site
            notified BOOLEAN DEFAULT 0
        )
    ''')

    self.cursor.execute('''
        CREATE INDEX IF NOT EXISTS idx_published_at
        ON listings(published_at)
    ''')
```

### Modifications √† add_listing()

```python
def add_listing(self, listing_data):
    """Ajouter une nouvelle annonce avec date de publication"""
    try:
        self.cursor.execute('''
            INSERT INTO listings
            (listing_id, site, title, city, price, rooms, surface,
             url, latitude, longitude, distance_km, published_at)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            listing_data.get('listing_id', ''),
            listing_data.get('site', 'Inconnu'),
            listing_data.get('title', 'Sans titre'),
            listing_data.get('city', 'N/A'),
            listing_data.get('price', 0),
            listing_data.get('rooms', 0),
            listing_data.get('surface', 0),
            listing_data.get('url', '#'),
            listing_data.get('latitude'),
            listing_data.get('longitude'),
            listing_data.get('distance_km'),
            listing_data.get('published_at')  # ‚Üê NOUVEAU
        ))
        self.conn.commit()
        return True
    except sqlite3.IntegrityError:
        return False
    except sqlite3.Error as e:
        logger.error(f"‚ùå Erreur ajout annonce: {e}")
        return False
```

### Nouvelle m√©thode pour query par date

```python
def get_listings_by_date(self, hours=24, limit=50):
    """R√©cup√©rer annonces publi√©es dans les X derni√®res heures"""
    try:
        from datetime import datetime, timedelta
        cutoff = datetime.now() - timedelta(hours=hours)

        self.cursor.execute('''
            SELECT listing_id, site, title, city, price, published_at
            FROM listings
            WHERE published_at >= ?
            ORDER BY published_at DESC
            LIMIT ?
        ''', (cutoff, limit))

        return self.cursor.fetchall()
    except sqlite3.Error as e:
        logger.error(f"‚ùå Erreur query: {e}")
        return []
```

---

## Modifications aux scrapers

### Fonction CRITIQUE : ensure_published_at()

**‚≠ê AJOUTER** d'abord cette fonction en `utils.py` :

```python
from datetime import datetime, timedelta
import re

def ensure_published_at(published_at=None):
    """
    ‚≠ê‚≠ê‚≠ê FONCTION CRITIQUE ‚≠ê‚≠ê‚≠ê
    Garantir que published_at a TOUJOURS une valeur valide.
    C'est le fallback central pour TOUS les scrapers.

    Logique:
    1. Si published_at valide et <= now() ‚Üí retourner
    2. Si None ou invalide ou future ‚Üí retourner now()

    Retourne TOUJOURS une datetime (jamais None).
    """
    if published_at is None:
        return datetime.now()

    # V√©rifier type
    if not isinstance(published_at, datetime):
        return datetime.now()

    # V√©rifier que pas dans le futur (correction bug)
    now = datetime.now()
    if published_at > now:
        # Annonce avec date future ‚Üí corriger √† maintenant
        return now

    # OK: retourner date valide
    return published_at

def parse_relative_date(text):
    """
    Parser texte "il y a X jours" et retourner datetime

    G√®re:
    - "Il y a 2 heures" ‚Üí datetime.now() - 2h
    - "Il y a 1 jour" ‚Üí datetime.now() - 1 jour
    - "R√©cemment" ‚Üí datetime.now()
    - "Aujourd'hui" ‚Üí datetime.now()
    """
    if not text:
        return None

    text_lower = text.lower()

    # "R√©cemment", "Aujourd'hui"
    if 'r√©cemment' in text_lower or 'aujourd' in text_lower or 'recent' in text_lower:
        return datetime.now()

    # "Il y a X heures/jours/semaines"
    match = re.search(r'(\d+)\s*(?:heure|jour|semaine|mois)s?', text_lower)
    if match:
        number = int(match.group(1))
        if 'heure' in match.group(0):
            return datetime.now() - timedelta(hours=number)
        elif 'jour' in match.group(0):
            return datetime.now() - timedelta(days=number)
        elif 'semaine' in match.group(0):
            return datetime.now() - timedelta(weeks=number)
        elif 'mois' in match.group(0):
            return datetime.now() - timedelta(days=number*30)

    return None

def parse_absolute_date(date_str, format_str="%d/%m/%Y"):
    """Parser date absolue (ex: "26/02/2026")"""
    try:
        return datetime.strptime(date_str, format_str)
    except:
        return None

def parse_iso_date(date_str):
    """Parser ISO 8601 (ex: "2026-02-26T09:45:00Z")"""
    try:
        return datetime.fromisoformat(date_str.replace('Z', '+00:00'))
    except:
        return None
```

### Exemple pour Athome.lu (avec fallback)

**Fichier** : `scrapers/athome_scraper_json.py`

```python
from utils import ensure_published_at, parse_iso_date, parse_relative_date

def _extract_listing(self, item):
    """Extraire donn√©es + DATE DE PUBLICATION avec fallback"""
    ...
    # √Ä la fin de la fonction, avant return:

    # √âtape 1: Chercher date de publication (peut √™tre None)
    published_at = None
    for key in ['publishDate', 'createdAt', 'timestamp', 'time_ago']:
        if key in item:
            value = item[key]
            if key == 'timestamp' and isinstance(value, (int, float)):
                # Timestamp Unix
                try:
                    published_at = datetime.fromtimestamp(value / 1000)  # /1000 si en ms
                    break
                except:
                    pass
            elif isinstance(value, str):
                # ISO date ou texte relatif
                published_at = parse_iso_date(value) or parse_relative_date(value)
                if published_at:
                    break

    # √âtape 2: FALLBACK GARANTI (jamais None apr√®s cette ligne)
    published_at = ensure_published_at(published_at)

    return {
        'listing_id': f'athome_{id_val}',
        'site': 'Athome.lu',
        'title': title,
        'city': city,
        'price': price,
        'rooms': rooms,
        'surface': surface,
        'url': url,
        'image_url': image_url,
        'latitude': lat,
        'longitude': lng,
        'distance_km': distance_km,
        'time_ago': 'R√©cemment',
        'published_at': published_at  # ‚Üê JAMAIS None (fallback √† datetime.now())
    }
```

### Exemple pour Immotop.lu

**Fichier** : `scrapers/immotop_scraper_real.py`

```python
def scrape(self):
    ...
    for match in matches:
        titre_raw, type_raw, prix_raw, url_rel, id_str, lat, lng, thumb_raw = match

        # Extraire date depuis le texte carte
        # Format: <div class="date">Il y a 2 heures</div>
        # √Ä chercher dans page_source via regex
        date_pattern = rf'id["\']={id_str}[^>]*>.*?[Ii]l y a (\d+\s*\w+)'
        date_match = re.search(date_pattern, self.page_source, re.DOTALL)

        published_at = None
        if date_match:
            date_text = date_match.group(1)
            published_at = parse_relative_date(f"Il y a {date_text}")

        listing = {
            ...
            'published_at': published_at  # ‚Üê NOUVEAU
        }
```

---

## Int√©gration dans le dashboard

### Requ√™te SQL pour dashboard

```python
# main.py ou dashboard.py
def get_dashboard_data():
    """R√©cup√©rer annonces pour dashboard"""
    from database import db
    from datetime import datetime, timedelta

    # Annonces publi√©es dans les 24 derni√®res heures
    listings = db.get_listings_by_date(hours=24, limit=100)

    # Formater pour dashboard
    data = []
    for listing in listings:
        listing_id, site, title, city, price, published_at = listing

        if published_at:
            # Formater temps √©coul√©
            now = datetime.now()
            delta = now - published_at
            if delta.total_seconds() < 3600:
                time_str = f"{int(delta.total_seconds() / 60)} min"
            elif delta.total_seconds() < 86400:
                time_str = f"{int(delta.total_seconds() / 3600)} h"
            else:
                time_str = f"{int(delta.total_seconds() / 86400)} j"
        else:
            time_str = "N/A"
            published_at = "N/A"

        data.append({
            'published_at': published_at,
            'time_str': time_str,
            'site': site,
            'title': title,
            'city': city,
            'price': price,
        })

    return sorted(data, key=lambda x: x['published_at'] or datetime.min, reverse=True)
```

### Format HTML pour dashboard

```html
<table class="listings">
  <thead>
    <tr>
      <th>üìÖ Publi√©</th>
      <th>Site</th>
      <th>Titre</th>
      <th>Ville</th>
      <th>Prix</th>
    </tr>
  </thead>
  <tbody>
    {% for listing in listings %}
    <tr class="{% if listing.time_str|contains('min') %}new-today{% elif listing.time_str|contains('h') %}today{% else %}older{% endif %}">
      <td>
        <span title="{{ listing.published_at }}">{{ listing.time_str }}</span>
      </td>
      <td>{{ listing.site }}</td>
      <td>{{ listing.title }}</td>
      <td>{{ listing.city }}</td>
      <td>{{ listing.price }}‚Ç¨</td>
    </tr>
    {% endfor %}
  </tbody>
</table>
```

### CSS pour highlight nouvelles annonces

```css
tr.new-today {
    background-color: #fff3cd;  /* Jaune clair */
    font-weight: bold;
}

tr.today {
    background-color: #f8f9fa;  /* Gris tr√®s clair */
}

tr.older {
    background-color: #fff;
}

/* Colorer par site */
tr[data-site="Nextimmo.lu"] { border-left: 4px solid #FF6B35; }
tr[data-site="Athome.lu"] { border-left: 4px solid #004E89; }
tr[data-site="VIVI.lu"] { border-left: 4px solid #A23B72; }
```

---

## Plan d'ex√©cution (√©tapes)

### Phase 1 : Analyse d√©taill√©e (2h)

**Objectif** : D√©terminer exactement o√π est la date dans chaque scraper

```bash
# Pour chaque scraper, faire test manuel:

# 1. Athome.lu
python3 << 'EOF'
from scrapers.athome_scraper_json import athome_scraper_json
import json

listings = athome_scraper_json.scrape()
if listings:
    print("Premier listing Athome:")
    print(json.dumps(listings[0], indent=2, default=str))
EOF

# 2. Nextimmo.lu
python3 << 'EOF'
from scrapers.nextimmo_scraper import nextimmo_scraper
import json

listings = nextimmo_scraper.scrape()
if listings:
    print("Premier listing Nextimmo:")
    print(json.dumps(listings[0], indent=2, default=str))
EOF

# M√™me chose pour tous les 7 scrapers
# Chercher : publishDate, createdAt, timestamp, time_ago, date, etc.
```

**Livrable** : Document "DATE_SOURCES_FOUND.md" listant cl√© + format pour chaque scraper

---

### Phase 2 : Cr√©er fonctions utilitaires (1h)

**Fichier** : `utils.py`

**Ajouter** :
```python
def parse_relative_date(text)
def parse_absolute_date(date_str, format_str)
def parse_iso_date(date_str)
```

**Tester** :
```bash
python test_date_parsing.py
# ‚úÖ Tester avec:
#   - "Il y a 2 heures" ‚Üí datetime.now() - 2h
#   - "Il y a 1 jour" ‚Üí datetime.now() - 1j
#   - "26/02/2026" ‚Üí datetime(2026, 2, 26)
#   - "2026-02-26T09:45:00Z" ‚Üí datetime(2026, 2, 26, 9, 45)
```

---

### Phase 3 : Modifier base de donn√©es (30 min)

**Fichier** : `database.py`

```python
# 1. Ajouter colonne published_at dans init_db()
# 2. Ajouter published_at dans add_listing()
# 3. Cr√©er index idx_published_at
# 4. Ajouter m√©thode get_listings_by_date()
```

**Migrate existing DB** (optionnel) :
```bash
sqlite3 listings.db << 'EOF'
ALTER TABLE listings ADD COLUMN published_at TIMESTAMP;
CREATE INDEX idx_published_at ON listings(published_at);
EOF
```

---

### Phase 4 : Modifier 7 scrapers (3h)

**Pour chaque scraper** :

```bash
# 1. √âditer scrapers/xxx_scraper.py
# 2. Ajouter extraction date dans _extract_listing() ou √©quivalent
# 3. Ajouter 'published_at': published_at au return

# 2. Tester scraper:
python3 << 'EOF'
from scrapers.xxx_scraper import xxx_scraper
listings = xxx_scraper.scrape()
if listings:
    print(f"‚úÖ {len(listings)} listings")
    print(f"Sample published_at: {listings[0].get('published_at')}")
EOF
```

**Ordre de priorit√©** :
1. Nextimmo (API propre) ‚Äî 20 min
2. Immotop (texte visible) ‚Äî 20 min
3. VIVI (Selenium HTML) ‚Äî 20 min
4. Athome (JSON) ‚Äî 20 min
5. Newimmo (regex) ‚Äî 15 min
6. Unicorn (regex) ‚Äî 15 min
7. Luxhome (regex/JSON) ‚Äî 15 min

---

### Phase 5 : Tester qualit√© donn√©es (1h)

```bash
# Cr√©er test_date_quality.py
python test_date_quality.py

# V√©rifie:
# ‚úÖ Toutes les annonces ont published_at
# ‚úÖ published_at <= created_at (DB timestamp)
# ‚úÖ published_at dans les 30 jours (pas ancien)
# ‚úÖ Pas de published_at dans le futur
```

---

### Phase 6 : Int√©grer dans dashboard (2h)

**Fichier** : `dashboard.py` (cr√©er si absent)

```python
from database import db
from datetime import datetime, timedelta

def render_dashboard():
    """Afficher annonces par date"""
    listings = db.get_listings_by_date(hours=24*7)  # 7 derniers jours

    # Grouper par date
    by_date = {}
    for listing in listings:
        date_key = listing['published_at'].date()
        if date_key not in by_date:
            by_date[date_key] = []
        by_date[date_key].append(listing)

    # Afficher HTML
    html = "<table>..."
    for date in sorted(by_date.keys(), reverse=True):
        html += f"<h3>{date.strftime('%d/%m/%Y')}</h3>"
        for listing in by_date[date]:
            html += f"<tr>...</tr>"

    return html
```

---

### Phase 7 : Validation et d√©ploiement (30 min)

```bash
# 1. V√©rifier toutes les donn√©es en BD
sqlite3 listings.db << 'EOF'
SELECT COUNT(*), COUNT(published_at) FROM listings;
SELECT MIN(published_at), MAX(published_at) FROM listings;
SELECT site, COUNT(*) FROM listings GROUP BY site;
EOF

# 2. Tester dashboard
python main.py  # V√©rifier logs

# 3. Committer
git add utils.py database.py scrapers/ dashboard.py
git commit -m "Add publication date tracking for all listings"
```

---

## R√©capitulatif timeline

| Phase | T√¢che | Temps | D√©pendances |
|-------|-------|-------|-------------|
| **1** | Analyser sources date | 2h | - |
| **2** | Fonctions utilitaires date | 1h | Phase 1 |
| **3** | Modifier base de donn√©es | 30 min | Phase 2 |
| **4** | Modifier 7 scrapers | 3h | Phase 2-3 |
| **5** | Tests qualit√© | 1h | Phase 4 |
| **6** | Int√©grer dashboard | 2h | Phase 5 |
| **7** | Validation | 30 min | Phase 6 |
| **TOTAL** | | **10h** | |

---

## üéØ R√©sultat final

### Dashboard avec date

```
üìÖ TABLEAU ANNONCES TRI√âES PAR DATE

Aujourd'hui (26/02/2026)
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
 ‚è∞ 09:45  ‚îÇ Athome  ‚îÇ 2ch, 1250‚Ç¨ ‚îÇ Luxembourg ‚îÇ ‚ú® √Ä peine 5 min
 ‚è∞ 08:15  ‚îÇ Nextimmo‚îÇ 3ch, 1800‚Ç¨ ‚îÇ Esch ‚îÇ ‚ú® 3h ago
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

Hier (25/02/2026)
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
 ‚è∞ 19:30  ‚îÇ VIVI    ‚îÇ 2ch, 1500‚Ç¨ ‚îÇ Differdange ‚îÇ
 ‚è∞ 14:20  ‚îÇ Luxhome ‚îÇ 1ch, 900‚Ç¨  ‚îÇ Dudelange ‚îÇ
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

Il y a 2 jours (24/02/2026)
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
 ‚è∞ 10:00  ‚îÇ Immotop ‚îÇ 2ch, 1400‚Ç¨ ‚îÇ Luxembourg ‚îÇ
```

### Filtrage possible

```
Filter: Derni√®res 24h ‚úÖ ‚Üí 2 annonces
Filter: Derni√®res 48h ‚úÖ ‚Üí 4 annonces
Filter: Derni√®re semaine ‚úÖ ‚Üí 5 annonces
```

### Bot + Notification

```
"Nouvelle annonce trouv√©e!
 Publi√©e il y a 5 minutes
 Athome.lu | 2ch, 1250‚Ç¨, Luxembourg"
```

---

**Cr√©√©** : 2026-02-26
**√âtapes** : 7 phases, 10h total
**Statut** : Pr√™t pour ex√©cution

